

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Dataset and Model Exploration Log &mdash; ProjektDepth - vathos üê≤ master documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> ProjektDepth - vathos üê≤
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Package Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="model.html">vathos.model</a></li>
<li class="toctree-l1"><a class="reference internal" href="data_loader.html">vathos.data_loader</a></li>
<li class="toctree-l1"><a class="reference internal" href="trainer.html">vathos.trainer</a></li>
<li class="toctree-l1"><a class="reference internal" href="runner.html">vathos.runner</a></li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">vathos.utils</a></li>
</ul>
<p class="caption"><span class="caption-text">The Journey</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="thejourney.html">Vathos üê≤ - The Journey</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">ProjektDepth - vathos üê≤</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>Dataset and Model Exploration Log</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/Dataset-Model-Exploration.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="dataset-and-model-exploration-log">
<h1>Dataset and Model Exploration Log<a class="headerlink" href="#dataset-and-model-exploration-log" title="Permalink to this headline">¬∂</a></h1>
<div class="section" id="ideas">
<h2>Ideas<a class="headerlink" href="#ideas" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>Train the model on <code class="docutils literal notranslate"><span class="pre">96x96</span></code> images then move on to larger
<code class="docutils literal notranslate"><span class="pre">192x192</span></code> images, since i made the images dataset of <code class="docutils literal notranslate"><span class="pre">200x200</span></code>
i‚Äôll have to resize them, dumb me, should have thought of taking the
size in multiple of <code class="docutils literal notranslate"><span class="pre">32</span></code>, that‚Äôs what the GPU üíñs.</p></li>
<li><p>Encoder-Decoder Model ? might be overkill ? should try it though, but
seems like i could get away without using ED model</p></li>
<li><p>Go through the various loss functions:
<a class="reference external" href="https://pytorch.org/docs/stable/nn.html#loss-functions">https://pytorch.org/docs/stable/nn.html#loss-functions</a></p></li>
<li><p>First train the network images (Encoder) so it learns to identify the
objects and segment them, then teach the network to do depth
estimation on large images as well as segmentation. - [X] Nope we‚Äôll
train the entire model with smaller images first and then train with
large images</p></li>
<li><p><a class="reference external" href="https://github.com/fastai/fastai/blob/master/fastai/layers.py#L202">https://github.com/fastai/fastai/blob/master/fastai/layers.py#L202</a>
read this to understand how to initialize the pixel shuffle</p></li>
<li><p>Use
<a class="reference external" href="https://github.com/OniroAI/MonoDepth-PyTorch/blob/master/models_resnet.py">https://github.com/OniroAI/MonoDepth-PyTorch/blob/master/models_resnet.py</a>
for reference</p></li>
<li><p>Use PreActivated ResNetV2, since its proven to be working better</p></li>
</ul>
<p>There are so many mistakes in sir‚Äôs code, why did he use interpolation ?
why not use deconvolution ? it will not introduce the checkerboard
issue. I figures i should use PixelShuffle, let‚Äôs see how good it works</p>
<ul class="simple">
<li><p>Use Pixel Shuffel algorithm to increase resolution</p></li>
<li><p>Maybe Use DepthWise Separation Convolution (MobileNet uses this)</p></li>
<li><p>Use ResNeXt like architecture, let each kernel choose which object to
segment</p></li>
<li><p>Use IoU as a metric to tell how good my model is</p></li>
<li><p>Try DiceLoss ?</p></li>
<li><p>Try BCE Loss ?</p></li>
<li><p>Try DICE + BCE Loss</p></li>
<li><p>Try Jaccard Loss ? (Hybrid Loss as mentioned in Stacked Unet)</p></li>
<li><p>Try image gradient loss ? from here
<a class="reference external" href="https://github.com/wolverinn/Depth-Estimation-PyTorch">https://github.com/wolverinn/Depth-Estimation-PyTorch</a></p></li>
<li><p>Read this
<a class="reference external" href="https://heartbeat.fritz.ai/research-guide-for-depth-estimation-with-deep-learning-1a02a439b834">https://heartbeat.fritz.ai/research-guide-for-depth-estimation-with-deep-learning-1a02a439b834</a></p></li>
<li><p>Study
<a class="reference external" href="https://github.com/wolverinn/Depth-Estimation-PyTorch/blob/master/fyn_main.py">https://github.com/wolverinn/Depth-Estimation-PyTorch/blob/master/fyn_main.py</a></p></li>
<li><p>Sudy UNet</p></li>
<li><p>Study ResNeXt</p></li>
<li><p>Add a pre convolution</p></li>
</ul>
<p>Higher Batch Size, Higher Learning Rate</p>
<p>Make Unet-Resnet Architecture, Then add Pixel Shuffling, Then use
ResNeXt</p>
<p>Combine all these ideas to make the final model, All the best</p>
</div>
<div class="section" id="todo">
<h2>TODO<a class="headerlink" href="#todo" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>[x] Make Unet-Resnet</p></li>
<li><p>[ ] Try the different loss functions</p></li>
<li><p>[x] Add Pixel Shuffling</p></li>
<li><p>[x] Check if everything works with ResNet and smaller dataset</p></li>
<li><p>[x] Add ResNeXt</p></li>
<li><p>[ ] Try DataAugmentation</p></li>
<li><p>[ ] [STRIKEOUT:Check if everything works with ResNeXt with smaller
dataset]</p></li>
<li><p>[x] Create a Deeper Network</p></li>
<li><p>[x] Reduce the Filters on the Segmentation Decoder</p></li>
<li><p>[ ] Make the library</p></li>
<li><p>[ ] Add save model checkpoint</p></li>
<li><p>[ ] Add Tensorboard</p></li>
<li><p>[ ] Train ! Train ! Train !</p></li>
</ul>
</div>
<div class="section" id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline">¬∂</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">Encoding</span> <span class="pre">-&gt;</span> <span class="pre">Bridge</span> <span class="pre">-&gt;</span> <span class="pre">Decoder1</span>&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160; <span class="pre">-&gt;</span> <span class="pre">Decoder2</span></code></p>
</div>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>70-30 train-test split</p></li>
</ul>
</div>
<div class="section" id="notes">
<h2>Notes<a class="headerlink" href="#notes" title="Permalink to this headline">¬∂</a></h2>
<ol class="arabic simple">
<li><p>All convolution operations are with 3*3 filters and with the SAME
padding thus the size of the feature map remains the same on each
level of contracting path and corresponding expanding path. With the
same padding, the boundary information is preserved and it also
allows for more convolutions to be added.</p></li>
<li><p>Because the feature size remains the same on a single level, cropping
of the feature map from the contracting path is not required in order
to concatenate with the corresponding feature map of the expanding
path. No cropping means no loss of information.</p></li>
<li><p>Along with the long skip connection between every level of
contracting and expanding paths, we have local skip connection
between convolutions on each level. Skip connection helps in getting
a smooth loss curve and also helps to avoid gradient disappearance
and explosion.</p></li>
</ol>
</div>
<div class="section" id="colab-accounts-management">
<h2>Colab Accounts Management<a class="headerlink" href="#colab-accounts-management" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>Dataset Referenced Links : <a class="reference external" href="mailto:shadowleaf&#46;deeplearning&#37;&#52;&#48;gmail&#46;com">shadowleaf<span>&#46;</span>deeplearning<span>&#64;</span>gmail<span>&#46;</span>com</a></p></li>
<li><p>Actual Dataset: <a class="reference external" href="mailto:shadowleaf&#46;contact&#37;&#52;&#48;gmail&#46;com">shadowleaf<span>&#46;</span>contact<span>&#64;</span>gmail<span>&#46;</span>com</a></p></li>
<li><p>Notebooks: <a class="reference external" href="mailto:shadowleaf&#46;contact&#37;&#52;&#48;gmail&#46;com">shadowleaf<span>&#46;</span>contact<span>&#64;</span>gmail<span>&#46;</span>com</a></p></li>
</ul>
</div>
<div class="section" id="further-improvements">
<h2>Further Improvements<a class="headerlink" href="#further-improvements" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>Try better quality images dataset, probably i compressed the jpeg too
much</p></li>
</ul>
</div>
<div class="section" id="targets">
<h2>Targets<a class="headerlink" href="#targets" title="Permalink to this headline">¬∂</a></h2>
<ul class="simple">
<li><p>11th May - Research about the possible models</p></li>
<li><p>12th May - Research about the shortlisted models</p></li>
<li><p>13th May - Create Models Conceptually, Research on Possible Loss
Functions</p></li>
<li><p>14th May - Implement the Models and create the smaller dataset of
96x96</p></li>
<li><p>15th May - Try different loss functions and train with smaller
dataset, [STRIKEOUT:Create the library therefore with Tensorboard]</p></li>
<li><p>16th May - [STRIKEOUT:Train Train Train] Failed at running the model</p></li>
<li><p>17th May - [STRIKEOUT:Train Train Train] Failed at running the model</p></li>
<li><p>18th May - The model works ! no memory leaks !</p></li>
<li><p>19th May - Tested the model works on TPU, reduced time by half, lower
the model size ? create the library, fix the model</p></li>
<li><p>20th May - Create the library and train on<code class="docutils literal notranslate"><span class="pre">96x96</span></code></p></li>
</ul>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Satyajit Ghana

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>